{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Decision Trees\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, 2:]\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth = 2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max_depth = nb of layer of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file = os.path.join(\"iris_tree.dot\"),\n",
    "        feature_names = iris.feature_names[2:],\n",
    "        class_names = iris.target_names,\n",
    "        rounded = True,\n",
    "        filled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini impurity : pure (=0) if all training instances belong to the same class.  \n",
    "$G_i = 1 - \\sum_{k=1}^{n} p_{i,k}^2$   \n",
    "$p_{i,k}$ is the ratio of class k instances among the training instances in the $i^{th}$ node (see iris_tree.png for more clarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating Class probabilities\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5,1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5,1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART Training algorithm\n",
    "---\n",
    "Classification And Regression Tree  \n",
    "\n",
    "Gini Impurity or Entropy\n",
    "Entropy :  \n",
    "$H_i = - \\sum_{k=1}^{n} \\log_2 (p_{i,k}) $ with $p_{i,k} != 0$  \n",
    "\n",
    "few differences in results between the 2 measures, \n",
    " * Gini = isolate the most frequent class in its own branch\n",
    " * Entropy = produce more balanced trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization\n",
    "---\n",
    "If it left unconstrained a tree model is likely to overfit because the number of parameters is not determined prior to the training unlike linear model, so the model is free to stick closely to the data.\n",
    "So regularization is necessary at least with max_depth, (other way the tree will have by default infinite branches)\n",
    "Other parameter that could serve regularization :\n",
    " * min_samples_split : minimum number of sample of a node must have before it splits\n",
    " * min_samples_leaf : minimum number of sample of a leaf node must have\n",
    " * min_weight_fraction_leaf : same as min_samples_leaf but expressed in a fraction of the total number of weight instances\n",
    " * max_leaf_nodes\n",
    " * max_features : the max number of features that are evaluated for splitting each node\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ml_env': venv)",
   "language": "python",
   "name": "python36964bitmlenvvenv3e1c4eb64ad245ec95301f66a304f99a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
