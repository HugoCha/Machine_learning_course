{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chap_3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-6d6f8491ec6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchap_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitanic_exo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chap_3'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = \"spam_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_ham_string(x, spam_or_ham):\n",
    "    if (spam_or_ham != \"spam\" and spam_or_ham!=\"ham\"):\n",
    "        print(\"Error in input string\")\n",
    "        return False\n",
    "    if spam_or_ham in x:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spam_ham_name(all_folders):\n",
    "    spam_folders = list(filter((lambda x: spam_ham_string(x, \"spam\")), all_folders))\n",
    "    ham_folders = list(filter((lambda x: spam_ham_string(x, \"ham\")), all_folders))\n",
    "    return ([spam_folders, ham_folders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spam_ham_name(datasets_folder):\n",
    "    current_folder_path = os.path.abspath(os.getcwd()) + \"/\"\n",
    "    dataset_path = current_folder_path + datasets_folder + \"/\"\n",
    "    all_folders = os.listdir(dataset_path)\n",
    "    \n",
    "    spam_folders, ham_folders = split_spam_ham_name(all_folders)\n",
    "    \n",
    "    spam_folders_path = [dataset_path + folder + \"/\" for folder in spam_folders]\n",
    "    ham_folders_path = [dataset_path + folder + \"/\" for folder in ham_folders]\n",
    "    \n",
    "    return [spam_folders_path, ham_folders_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_folders_path, ham_folders_path = extract_spam_ham_name(datasets_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20030228_spam_2/',\n",
       " '/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20021010_spam/',\n",
       " '/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20030228_spam/']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_folders_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20030228_easy_ham_2/',\n",
       " '/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20030228_hard_ham/',\n",
       " '/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20030228_easy_ham/',\n",
       " '/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20021010_easy_ham/',\n",
       " '/home/hugo/Machine_learning/Machine_learning_course/chap_3/spam_datasets/20021010_hard_ham/']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_folders_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_header_content(raw_text):\n",
    "    separator_pattern = re.compile(r\"\\n\\n\")\n",
    "    mail = separator_pattern.split(raw_text, maxsplit=1)\n",
    "    if len(mail)==1:\n",
    "        print(mail)\n",
    "    heading = mail[0]\n",
    "    content = mail[1]\n",
    "    header_in_content = False\n",
    "    while(content != \"\" and header_in_content):\n",
    "        header_in_content = False\n",
    "        for pattern in heading_pattern:\n",
    "            if pattern.match(content) != None:\n",
    "                mail = separator_pattern.split(content, maxsplit=1)\n",
    "                header_in_content = True\n",
    "                content = mail[1]\n",
    "                heading = heading + mail[0]\n",
    "    \n",
    "    return (heading, content)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt(filepath):\n",
    "    try:\n",
    "        f = open(filepath, \"r\", encoding='utf8', errors='replace')#, \n",
    "        text = f.read()\n",
    "    except:\n",
    "        return (False, filepath)\n",
    "    return (True, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patterns in the heading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "received_pattern = re.compile(\"^Received:.*\\n\\t.*\\n\\t.*\\n|^Received:.*\\n\\t.*\\n|^Received:.*\\n\",\n",
    "                              flags=re.M|re.X)\n",
    "messageId_pattern = re.compile(\"^Message-ID:.*\\n\",\n",
    "                              flags=re.M|re.X)\n",
    "returnpath_pattern = re.compile(\"^Return-Path:.*\\n\",\n",
    "                              flags=re.M|re.X)\n",
    "from_pattern = re.compile(\"^From[:\\s].*\\n\",\n",
    "                         flags=re.M|re.X)\n",
    "deliver_pattern = re.compile(\"^Delivered-To:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "subject_pattern = re.compile(\"^Subject:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "date_pattern = re.compile(\"^Date:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "content_type_pattern = re.compile(\"^Content-Type:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "content_transfer_pattern = re.compile(\"^Content-Transfer-Encoding:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "content_pattern = re.compile(\"^Content-.*:.*\\n\",\n",
    "                            flags=re.M|re.X)\n",
    "mime_pattern = re.compile(\"^MIME-Version:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "bcc_pattern = re.compile(\"^Bcc:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "importance_pattern = re.compile(\"^Importance:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "to_pattern = re.compile(\"^To:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "xmailer_pattern = re.compile(\"^X-Mailer:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "xpriority_pattern = re.compile(\"^X-Priority:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "x_spam_pattern = re.compile(\"^X-Spam:.*\\n\",\n",
    "                           flags=re.M|re.X)\n",
    "x_pattern = re.compile(\"^X-.*:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "replyto_pattern = re.compile(\"^Reply-To:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "list_pattern = re.compile(\"^List-.*:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "errors_pattern = re.compile(\"^Errors:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "hyphen_to_pattern = re.compile(\"^[\\w\\-]+-To:.*\\n\", \n",
    "                            flags=re.M|re.X)\n",
    "\n",
    "heading_pattern = [\n",
    "    received_pattern, \n",
    "    messageId_pattern,\n",
    "    returnpath_pattern,\n",
    "    from_pattern,\n",
    "    deliver_pattern,\n",
    "    subject_pattern,\n",
    "    date_pattern,\n",
    "    content_type_pattern,\n",
    "    content_transfer_pattern,\n",
    "    mime_pattern,\n",
    "    bcc_pattern,\n",
    "    importance_pattern,\n",
    "    to_pattern,\n",
    "    xmailer_pattern,\n",
    "    xpriority_pattern,\n",
    "    x_spam_pattern,\n",
    "    x_pattern,\n",
    "    replyto_pattern,\n",
    "    list_pattern,\n",
    "    errors_pattern,\n",
    "    hyphen_to_pattern,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patterns in the content\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_pattern = re.compile(\"\\<.*?\\>\", re.S)\n",
    "URL_pattern = re.compile(\"http.*\\s\", re.I | re.X)\n",
    "mail_pattern = re.compile(\"\\w+@[\\w\\.]+\\W\", re.I)\n",
    "arrow_pattern = re.compile(\"^\\>\", re.M)\n",
    "price_pattern = re.compile(\"[\\$£]\\s{0,2}\\d+[,\\.]\\d+ | [\\$£]\\s{0,2}\\d+ | \\d+\\s{0,2}[$£] | \\d+[,\\.]\\d+\\s{0,2}[$£]\", re.X)\n",
    "one_two_letter_word_pattern = re.compile(r\"\\b[a-zA-Z]{1,2}\\b\", re.X | re.M)\n",
    "\n",
    "punctuation_pattern = re.compile(r\"[\\?\\!]\", re.X)\n",
    "hour_date_pattern = re.compile(\"\\d{4}\\s*[a-zA-Z]{2,8}\\s*\\d{1,2} | \\d{1,2}\\s*[a-zA-Z]{2,8}\\s*\\d{4} | \\d{1,2}:\\d{2}:\\d{2}\", re.X)\n",
    "\n",
    "maj_pattern = re.compile(\"[A-Z]\", re.X)\n",
    "number_pattern = re.compile(\"\\d+\", re.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General class to process heading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadPattern():\n",
    "    def __init__(self, pattern):\n",
    "        self.pattern = pattern\n",
    "        self.pattern_list = []\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return 0    \n",
    "    \n",
    "    def find(self, header):\n",
    "        self.pattern_list = self.pattern.findall(header)\n",
    "        \n",
    "    def isNone(self):\n",
    "        return (self.pattern_list == [])\n",
    "    \n",
    "    def display_pattern(self):\n",
    "        print(self.pattern_list)\n",
    "    \n",
    "    def len_list_pattern(self):\n",
    "        return (len(self.pattern_list))\n",
    "    \n",
    "    def processing(self, header):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General class to process content\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentPattern():\n",
    "    def __init__(self, pattern):\n",
    "        self.pattern = pattern\n",
    "        self.pattern_list = []\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return 0    \n",
    "    \n",
    "    def find(self, content):\n",
    "        self.pattern_list = self.pattern.findall(content)\n",
    "        \n",
    "    def isNone(self):\n",
    "        return (self.pattern_list == [])\n",
    "    \n",
    "    def display_pattern(self):\n",
    "        print(self.pattern_list)\n",
    "    \n",
    "    def len_list_pattern(self):\n",
    "        return (len(self.pattern_list))\n",
    "    \n",
    "    def count(self, content):\n",
    "        self.find(content)\n",
    "        return (self.len_list_pattern())\n",
    "    \n",
    "    def replace(self, content):\n",
    "        new_content = self.pattern.sub(\"\", content)\n",
    "        return (new_content)\n",
    "    \n",
    "    def count_replace(self, content):\n",
    "        pattern_nb = 0\n",
    "        new_content, pattern_nb = self.pattern.subn(\"\", content)\n",
    "        return (new_content, pattern_nb)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subclasses for processing\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FromPattern(HeadPattern):\n",
    "    def __init__(self):\n",
    "        HeadPattern.__init__(self, from_pattern)\n",
    "    \n",
    "    def processing(self, header):\n",
    "        self.find(header)\n",
    "        name = ''\n",
    "        domain = ''\n",
    "        extension = ''\n",
    "        if (self.isNone() == False):\n",
    "            length = self.len_list_pattern()\n",
    "            for i in range(length):\n",
    "                mail_pattern1 = re.compile(\"(From:\\s)<?(?P<name>.*)@(?P<domain>.*)\\.(?P<extension>[\\w\\.]*)>?\", re.I)\n",
    "                #mail_pattern2 = re.compile(\"(From:\\s)(?P<name>.*)@(?P<domain>.*)\\.(?P<extension>.*)\", re.I)\n",
    "                mail_address = mail_pattern1.search(self.pattern_list[i])\n",
    "                #if (mail_address == None):\n",
    "                #    mail_address = mail_pattern2.search(self.pattern_list[i])\n",
    "                if (mail_address != None):\n",
    "                    name = mail_address.group('name')\n",
    "                    domain = mail_address.group('domain')\n",
    "                    extension = mail_address.group('extension')\n",
    "        len_name = len(name)\n",
    "        number_in_name = re.findall(\"\\d\", name)\n",
    "        if (number_in_name != None):\n",
    "            len_number_in_name = len(re.findall(\"\\d\", name))\n",
    "        else:\n",
    "            len_number_in_name = 0\n",
    "        return ([len_name, len_number_in_name, domain, extension])\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return (\"from\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatePattern(HeadPattern):\n",
    "    def __init__(self):\n",
    "        HeadPattern.__init__(self, date_pattern)\n",
    "    \n",
    "    def processing(self, header):\n",
    "        self.find(header)\n",
    "        hour = np.nan\n",
    "        if (self.isNone() == False):\n",
    "            hour_patt = re.compile(\"(?P<hour>\\d{1,2}):(?P<minute>\\d{2}):(?P<second>\\d{2})\")\n",
    "            hour_search = hour_patt.search(self.pattern_list[0])\n",
    "            hour = int(hour_search.group('hour')) if (hour_search!=None) else np.nan\n",
    "        return (hour)\n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentTypePattern(HeadPattern):\n",
    "    def __init__(self):\n",
    "        HeadPattern.__init__(self, content_type_pattern)\n",
    "    \n",
    "    def processing(self, header):\n",
    "        self.find(header)\n",
    "        content_type = np.nan\n",
    "        if (self.isNone() == False):\n",
    "            content_type_patt = re.compile(\"\"\"(Content-Type:)\\s(?P<type>.*)[;\\n]\"\"\", re.X)\n",
    "            content_type_match = content_type_patt.search(self.pattern_list[0])\n",
    "            content_type = content_type_match.group('type') if (content_type_match!=None) else np.nan\n",
    "        return (content_type)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"content-type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportancePattern(HeadPattern):\n",
    "    def __init__(self):\n",
    "        HeadPattern.__init__(self, importance_pattern)\n",
    "    \n",
    "    def processing(self, header):\n",
    "        self.find(header)\n",
    "        importance = np.nan\n",
    "        if (self.isNone() == False):\n",
    "            importance = self.pattern_list[0][12:]\n",
    "        return (importance)\n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XSpamPattern(HeadPattern):\n",
    "    def __init__(self):\n",
    "        HeadPattern.__init__(self, x_spam_pattern)\n",
    "    \n",
    "    def processing(self, header):\n",
    "        self.find(header)\n",
    "        x_spam_word = np.nan\n",
    "        if (self.isNone() == False):\n",
    "            x_spam_word = self.pattern_list[0][8:]\n",
    "        return (x_spam_word)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"x-spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class X_Pattern(HeadPattern):\n",
    "    def __init__(self):\n",
    "        HeadPattern.__init__(self, x_pattern)\n",
    "    \n",
    "    def processing(self, header):\n",
    "        self.find(header)\n",
    "        return (self.len_list_pattern())\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"x-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTMLPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, HTML_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count_replace(content)\n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, URL_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count_replace(content)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MailPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, mail_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count_replace(content)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrowPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, arrow_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count_replace(content)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"> count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricePattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, price_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count_replace(content)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PunctuationPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, punctuation_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count_replace(content)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"? or !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, number_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count_replace(content)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"Number count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HourDatePattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, hour_date_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.replace(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneTwoLetterWordPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, one_two_letter_word_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.replace(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, maj_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        return self.count(content)\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"Majuscule count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pattern = re.compile(\"\\\\b[\\w\\+\\-\\=\\&\\*]+\\\\b\", re.I | re.X)\n",
    "\n",
    "class WordPattern(ContentPattern):\n",
    "    def __init__(self):\n",
    "        ContentPattern.__init__(self, word_pattern)\n",
    "    \n",
    "    def processing(self, content):\n",
    "        self.find(content)\n",
    "        number_of_word = self.len_list_pattern()\n",
    "        len_word_list = list(map(len, self.pattern_list))\n",
    "        if len(len_word_list) != 0:\n",
    "            mean_len_word = round(sum(len_word_list)/len(len_word_list), 4)\n",
    "            longuest_word = max(len_word_list)\n",
    "        else:\n",
    "            mean_len_word = 0\n",
    "            longuest_word = 0\n",
    "        return (content, [number_of_word, mean_len_word, longuest_word])\n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"content_attr\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_all_word(content):\n",
    "    pattern = re.compile(\"\\w+\", re.I | re.X | re.M)\n",
    "    new_content = pattern.findall(content)\n",
    "    return new_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject is treated differently from other heading pattern as precious info could be extract from these\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectPattern(HeadPattern):\n",
    "    def __init__(self):\n",
    "        HeadPattern.__init__(self, subject_pattern)\n",
    "    \n",
    "    def processing(self, header):\n",
    "        self.find(header)\n",
    "        number_of_maj = 0\n",
    "        number_of_number = 0\n",
    "        number_of_char = 0\n",
    "        number_of_price = 0\n",
    "        number_of_special_char = 0\n",
    "        word_list = []\n",
    "        if (self.isNone() == False):\n",
    "            # Extract info on number of char in function of categories (maj, punctuation)\n",
    "            number_of_maj = len(re.findall(\"[A-Z]\", self.pattern_list[0])) - 1 #Subtract \"S\" of \"Subject\"\n",
    "            number_of_char = len(self.pattern_list[0]) - 8 #Subtract len(\"Subject:\"))\n",
    "            number_of_special_char = len(re.findall(\"[\\!\\?\\$]\", self.pattern_list[0]))\n",
    "            \n",
    "            # Extract info on number of char in function of categories (price,number)\n",
    "            # And replace by \"\" those pattern\n",
    "            new_subject, number_of_price = PricePattern().processing(self.pattern_list[0])\n",
    "            new_subject, number_of_number = NumberPattern().processing(new_subject)\n",
    "            # Replace all one or two letters word by \"\"\n",
    "            new_subject = OneTwoLetterWordPattern().processing(new_subject)\n",
    "            \n",
    "            # Extact all remaining words except Subject of course\n",
    "            new_subject = new_subject[8:]\n",
    "            word_list = isolate_all_word(new_subject)\n",
    "        \n",
    "        return ([number_of_maj, \n",
    "                 number_of_char, \n",
    "                 number_of_special_char, \n",
    "                 number_of_price, \n",
    "                 number_of_number, \n",
    "                 word_list])\n",
    "    \n",
    "    @property\n",
    "    def pattern_cat(self):\n",
    "        return(\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 45, 0, 0, 3, ['jzeidze', 'dzejdiuden', 'dedzi', 'jdeiz']]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Subject: jzeidze dzejdiude09909n dedzi 999jdeiz i9 JJ\"\n",
    "subj_patt = SubjectPattern()\n",
    "subj_extract = subj_patt.processing(string)\n",
    "subj_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_heading_pattern = [\n",
    "    FromPattern(),\n",
    "    SubjectPattern(),\n",
    "    DatePattern(),\n",
    "    ContentTypePattern(),\n",
    "    ImportancePattern(),\n",
    "    XSpamPattern(),\n",
    "    X_Pattern(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_heading(heading):\n",
    "    attributes = []\n",
    "    for important_pattern in important_heading_pattern:\n",
    "        attributes.append(important_pattern.processing(heading))\n",
    "    return attributes  #heading_dataframe.loc[len(heading_dataframe.index)] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_replace_content_pattern_list = [\n",
    "    HTMLPattern(),\n",
    "    URLPattern(),\n",
    "    MailPattern(),\n",
    "    PricePattern(),\n",
    "    ArrowPattern(),\n",
    "    PunctuationPattern(),\n",
    "    WordPattern(),\n",
    "    NumberPattern(),\n",
    "]\n",
    "\n",
    "replace_content_list = [\n",
    "    OneTwoLetterWordPattern(),\n",
    "    HourDatePattern(),\n",
    "]\n",
    "\n",
    "count_content_list = [\n",
    "    MajPattern(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content(content):\n",
    "    attributes = []\n",
    "    new_content = content\n",
    "    for count_repl_patt in count_replace_content_pattern_list:\n",
    "        new_content, count = count_repl_patt.processing(new_content)\n",
    "        attributes.append(count)\n",
    "    for repl_patt in replace_content_list:\n",
    "        new_content = repl_patt.processing(new_content)\n",
    "    for count_patt in count_content_list:\n",
    "        count = count_patt.processing(new_content)\n",
    "        attributes.append(count)\n",
    "    word_list = isolate_all_word(new_content)\n",
    "    attributes.append(word_list)\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_cat():\n",
    "    # Create Dataframe\n",
    "    mail_dataframe = pd.DataFrame()\n",
    "    \n",
    "    # Add a spam or not cat\n",
    "    mail_dataframe['spam']=[]\n",
    "    \n",
    "    # Add Heading Attributes\n",
    "    for important_pattern in important_heading_pattern:\n",
    "        mail_dataframe[important_pattern.pattern_cat]=[]\n",
    "    \n",
    "    # Add Content Attributes\n",
    "    for count_repl_patt in count_replace_content_pattern_list:\n",
    "        mail_dataframe[count_repl_patt.pattern_cat]=[]\n",
    "    for count_patt in count_content_list:\n",
    "        mail_dataframe[count_patt.pattern_cat]=[]\n",
    "    mail_dataframe['all words']=[]\n",
    "    \n",
    "    return mail_dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mail(raw_text, mail_dataframe, column_name_list, spam=True):\n",
    "    heading, content = separate_header_content(raw_text)\n",
    "    heading_attributes = process_heading(heading)\n",
    "    content_attributes = process_content(content)\n",
    "    mail_attributes =  [int(spam)] + heading_attributes + content_attributes\n",
    "    #len(mail_dataframe.index)\n",
    "    dict2add = dict(zip(column_name_list, mail_attributes))\n",
    "    #print(dict2add)\n",
    "    return mail_dataframe.append(dict2add, ignore_index=True)\n",
    "    #mail_dataframe.loc[] = mail_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_file(spam_folders_path, ham_folders_path, mail_dataframe=None):\n",
    "    if mail_dataframe == None:\n",
    "        # if no mail has been processed and saved before create dataframe\n",
    "        mail_dataframe = create_dataframe_cat()\n",
    "        \n",
    "    column_name_list = list(mail_dataframe.columns)\n",
    "    for folder_path in spam_folders_path:\n",
    "        under_path = folder_path + os.listdir(folder_path)[0] + \"/\"\n",
    "        file_list = os.listdir(under_path)\n",
    "        number2extract = 10*(len(file_list))//100\n",
    "        print(number2extract)\n",
    "        for file in file_list[len(file_list)-number2extract:]:\n",
    "            filepath = under_path + file\n",
    "            if (file!=\"cmds\"):\n",
    "                extraction, text = extract_txt(filepath)\n",
    "                if (extraction == True):\n",
    "                    mail_dataframe = process_mail(text, mail_dataframe,column_name_list, spam=True)\n",
    "                else:\n",
    "                    print(text)\n",
    "                #return 0\n",
    "            \n",
    "    for folder_path in ham_folders_path:\n",
    "        under_path = folder_path + os.listdir(folder_path)[0] + \"/\"\n",
    "        file_list = os.listdir(under_path)\n",
    "        number2extract = 7*(len(file_list))//100\n",
    "        print(number2extract)\n",
    "        for file in file_list[len(file_list)-number2extract:]:\n",
    "            filepath = under_path + file\n",
    "            if (file!=\"cmds\"):\n",
    "                extraction, text = extract_txt(filepath)\n",
    "                if (extraction == True):\n",
    "                    mail_dataframe = process_mail(text, mail_dataframe,column_name_list, spam=False)\n",
    "                else:\n",
    "                    print(text)\n",
    "                #return 0\n",
    "    return mail_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "50\n",
      "50\n",
      "98\n",
      "17\n",
      "175\n",
      "178\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "mail_dataframe = extract_data_from_file(spam_folders_path, ham_folders_path, mail_dataframe=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>hour</th>\n",
       "      <th>content-type</th>\n",
       "      <th>importance</th>\n",
       "      <th>x-spam</th>\n",
       "      <th>x-*</th>\n",
       "      <th>html</th>\n",
       "      <th>url</th>\n",
       "      <th>mail</th>\n",
       "      <th>price</th>\n",
       "      <th>&gt; count</th>\n",
       "      <th>? or !</th>\n",
       "      <th>content_attr</th>\n",
       "      <th>Number count</th>\n",
       "      <th>Majuscule count</th>\n",
       "      <th>all words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[17, 0, mail, com]</td>\n",
       "      <td>[5, 44, 4, 0, 3, [make, love, tonight, wDFrsxqw]]</td>\n",
       "      <td>18.0</td>\n",
       "      <td>text/html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[6, 3.6667, 5]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[open, click, here, see, more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[23, 1, ct2.consumertoday, net]</td>\n",
       "      <td>[4, 48, 1, 0, 0, [Complimentary, Thermal, Coff...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>multipart/alternative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[177, 5.2147, 63]</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[Content, Type, text, plain, charset, ascii, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[13, 2, address, com]</td>\n",
       "      <td>[3, 44, 0, 0, 1, [Your, application, below, Ex...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>text/html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[184, 4.8641, 47]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[Your, application, for, the, Grant, below, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[9, 4, hotmail, com]</td>\n",
       "      <td>[4, 37, 3, 0, 0, [Incredible, Cash, Generating...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[124, 4.3145, 14]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[Greetings, Like, most, have, been, burned, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[16, 0, TomGreen, com]</td>\n",
       "      <td>[9, 74, 0, 0, 0, [Free, Adult, DVDs, purchase,...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[165, 4.9636, 26]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[Adult, Online, Super, Store, Shhhhhh, You, ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[29, 0, tribute, ca]</td>\n",
       "      <td>[4, 31, 0, 0, 2, [Tribute, MovieMail, Vol]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>multipart/alternative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[2997, 3.6994, 27]</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>[This, multi, part, message, MIME, format, _Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[35, 0, DivX.at.krieger.mailshell, com]</td>\n",
       "      <td>[11, 64, 0, 0, 0, [DivX, News, Battle, the, Pl...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[768, 4.7044, 14]</td>\n",
       "      <td>18.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>[DivX, News, Number, What, Hot, the, World, Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[61, 9, newsletter.online, com]</td>\n",
       "      <td>[6, 42, 0, 0, 0, [Where, TabletPC, will, succe...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>text/html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[855, 5.1427, 19]</td>\n",
       "      <td>33.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>[Tech, Update, Today, VITAL, SIGNS, FOR, JULY,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[10, 0, mountainviewdata, com]</td>\n",
       "      <td>[0, 19, 0, 0, 0, [deadlock, problem]]</td>\n",
       "      <td>17.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[127, 4.9449, 15]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[XFS, developers, When, studying, xfs, code, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[24, 0, mediaunspun.imakenews, net]</td>\n",
       "      <td>[3, 16, 1, 0, 0, [United, Fall]]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>multipart/alternative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[2409, 4.9655, 25]</td>\n",
       "      <td>46.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>[This, multi, part, message, MIME, format, _, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     spam                                     from  \\\n",
       "0     1.0                       [17, 0, mail, com]   \n",
       "1     1.0          [23, 1, ct2.consumertoday, net]   \n",
       "2     1.0                    [13, 2, address, com]   \n",
       "3     1.0                     [9, 4, hotmail, com]   \n",
       "4     1.0                   [16, 0, TomGreen, com]   \n",
       "..    ...                                      ...   \n",
       "719   0.0                     [29, 0, tribute, ca]   \n",
       "720   0.0  [35, 0, DivX.at.krieger.mailshell, com]   \n",
       "721   0.0          [61, 9, newsletter.online, com]   \n",
       "722   0.0           [10, 0, mountainviewdata, com]   \n",
       "723   0.0      [24, 0, mediaunspun.imakenews, net]   \n",
       "\n",
       "                                               subject  hour  \\\n",
       "0    [5, 44, 4, 0, 3, [make, love, tonight, wDFrsxqw]]  18.0   \n",
       "1    [4, 48, 1, 0, 0, [Complimentary, Thermal, Coff...  19.0   \n",
       "2    [3, 44, 0, 0, 1, [Your, application, below, Ex...  18.0   \n",
       "3    [4, 37, 3, 0, 0, [Incredible, Cash, Generating...  12.0   \n",
       "4    [9, 74, 0, 0, 0, [Free, Adult, DVDs, purchase,...  18.0   \n",
       "..                                                 ...   ...   \n",
       "719        [4, 31, 0, 0, 2, [Tribute, MovieMail, Vol]]   0.0   \n",
       "720  [11, 64, 0, 0, 0, [DivX, News, Battle, the, Pl...  19.0   \n",
       "721  [6, 42, 0, 0, 0, [Where, TabletPC, will, succe...   6.0   \n",
       "722              [0, 19, 0, 0, 0, [deadlock, problem]]  17.0   \n",
       "723                   [3, 16, 1, 0, 0, [United, Fall]]   9.0   \n",
       "\n",
       "                     content-type importance x-spam   x-*    html   url  mail  \\\n",
       "0                       text/html        NaN    NaN   5.0    21.0   1.0   0.0   \n",
       "1           multipart/alternative        NaN    NaN   2.0     0.0   2.0   0.0   \n",
       "2                       text/html        NaN    NaN   1.0   121.0   2.0   1.0   \n",
       "3                             NaN        NaN    NaN   0.0     0.0   1.0   1.0   \n",
       "4                      text/plain        NaN    NaN   1.0     0.0   2.0   1.0   \n",
       "..                            ...        ...    ...   ...     ...   ...   ...   \n",
       "719         multipart/alternative        NaN    NaN   0.0  2025.0   2.0   0.0   \n",
       "720                    text/plain        NaN    NaN  10.0    14.0   3.0   0.0   \n",
       "721                     text/html        NaN    NaN   2.0  1009.0   1.0   2.0   \n",
       "722  text/plain; charset=us-ascii        NaN    NaN  10.0     0.0   0.0   0.0   \n",
       "723         multipart/alternative        NaN    NaN   4.0   678.0  52.0  17.0   \n",
       "\n",
       "     price  > count  ? or !        content_attr  Number count  \\\n",
       "0      0.0      0.0     0.0      [6, 3.6667, 5]           0.0   \n",
       "1      4.0      0.0     2.0   [177, 5.2147, 63]          11.0   \n",
       "2      1.0      1.0     9.0   [184, 4.8641, 47]           2.0   \n",
       "3      0.0      0.0     0.0   [124, 4.3145, 14]           3.0   \n",
       "4      1.0      1.0    15.0   [165, 4.9636, 26]           3.0   \n",
       "..     ...      ...     ...                 ...           ...   \n",
       "719    0.0      0.0    15.0  [2997, 3.6994, 27]        1432.0   \n",
       "720    1.0      0.0     4.0   [768, 4.7044, 14]          18.0   \n",
       "721    0.0      0.0     6.0   [855, 5.1427, 19]          33.0   \n",
       "722    0.0      0.0     1.0   [127, 4.9449, 15]           6.0   \n",
       "723   10.0      0.0    14.0  [2409, 4.9655, 25]          46.0   \n",
       "\n",
       "     Majuscule count                                          all words  \n",
       "0                0.0                     [open, click, here, see, more]  \n",
       "1               58.0  [Content, Type, text, plain, charset, ascii, C...  \n",
       "2               84.0  [Your, application, for, the, Grant, below, Re...  \n",
       "3               31.0  [Greetings, Like, most, have, been, burned, se...  \n",
       "4              104.0  [Adult, Online, Super, Store, Shhhhhh, You, ju...  \n",
       "..               ...                                                ...  \n",
       "719            498.0  [This, multi, part, message, MIME, format, _Ne...  \n",
       "720            226.0  [DivX, News, Number, What, Hot, the, World, Di...  \n",
       "721            372.0  [Tech, Update, Today, VITAL, SIGNS, FOR, JULY,...  \n",
       "722            105.0  [XFS, developers, When, studying, xfs, code, f...  \n",
       "723            816.0  [This, multi, part, message, MIME, format, _, ...  \n",
       "\n",
       "[724 rows x 18 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataframe to csv\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mail_dataframe.to_csv(os.path.abspath(os.getcwd()) + \"/mail_extract.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split categories in function of spam or not \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ham_spam_dataframe(mail_dataframe, cat2split):\n",
    "    spam = mail_dataframe.loc[mail_dataframe[\"spam\"] == 1.0][cat2split]\n",
    "    ham = mail_dataframe.loc[mail_dataframe[\"spam\"] == 0.0][cat2split] \n",
    "    ham.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return (spam, ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process subject\n",
    "spam_subject, ham_subject = split_ham_spam_dataframe(mail_dataframe, \"subject\")\n",
    "# Process content\n",
    "spam_content, ham_content = split_ham_spam_dataframe(mail_dataframe, \"all words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search top numbers_of_words of most used words\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_subject_redondant_word(subject_dataframe, number_of_words):\n",
    "    all_word_spam = []\n",
    "    for i in range(subject_dataframe.shape[0]):\n",
    "        all_word_spam += subject_dataframe[i][5]\n",
    "    spam_most_used_words = Counter(map(str.lower, all_word_spam)).most_common(number_of_words)\n",
    "    spam_most_used_words = [(i[0], round(i[1]/len(all_word_spam), 4)) for i in spam_most_used_words]\n",
    "    return spam_most_used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('your', 0.0348),\n",
       " ('the', 0.0196),\n",
       " ('free', 0.0187),\n",
       " ('you', 0.0187),\n",
       " ('for', 0.0161),\n",
       " ('home', 0.0134),\n",
       " ('adv', 0.0116),\n",
       " ('from', 0.0107),\n",
       " ('best', 0.008),\n",
       " ('with', 0.008),\n",
       " ('help', 0.008),\n",
       " ('mortgage', 0.0071),\n",
       " ('get', 0.0071),\n",
       " ('and', 0.0071),\n",
       " ('online', 0.0071),\n",
       " ('money', 0.0063),\n",
       " ('work', 0.0063),\n",
       " ('make', 0.0054),\n",
       " ('business', 0.0054),\n",
       " ('low', 0.0054)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_subject_most_used_words = search_subject_redondant_word(spam_subject, 20)\n",
    "spam_subject_most_used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ilug', 0.0235),\n",
       " ('for', 0.022),\n",
       " ('the', 0.022),\n",
       " ('razor', 0.0141),\n",
       " ('users', 0.0094),\n",
       " ('with', 0.0094),\n",
       " ('new', 0.0094),\n",
       " ('spambayes', 0.0094),\n",
       " ('satalk', 0.0089),\n",
       " ('zzzzteana', 0.0084),\n",
       " ('use', 0.0075),\n",
       " ('and', 0.007),\n",
       " ('perl', 0.0061),\n",
       " ('was', 0.0061),\n",
       " ('spam', 0.0056),\n",
       " ('sadev', 0.0052),\n",
       " ('apt', 0.0052),\n",
       " ('spamassassin', 0.0047),\n",
       " ('stories', 0.0042),\n",
       " ('lockergnome', 0.0042)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_subject_most_used_words = search_subject_redondant_word(ham_subject, 20)\n",
    "ham_subject_most_used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_content_redondant_word(word_dataframe, number_of_words):\n",
    "    all_word_spam = []\n",
    "    for i in range(word_dataframe.shape[0]):\n",
    "        all_word_spam += word_dataframe[i]\n",
    "    spam_most_used_words = Counter(map(str.lower, all_word_spam)).most_common(number_of_words)\n",
    "    spam_most_used_words = [(i[0], round(i[1]/len(all_word_spam), 4)) for i in spam_most_used_words]\n",
    "    return spam_most_used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.0344),\n",
       " ('you', 0.0292),\n",
       " ('and', 0.0259),\n",
       " ('for', 0.0156),\n",
       " ('your', 0.0143),\n",
       " ('this', 0.0126),\n",
       " ('nbsp', 0.0122),\n",
       " ('that', 0.0081),\n",
       " ('with', 0.0076),\n",
       " ('are', 0.0073),\n",
       " ('will', 0.0072),\n",
       " ('email', 0.0065),\n",
       " ('from', 0.0065),\n",
       " ('our', 0.0063),\n",
       " ('have', 0.0063),\n",
       " ('free', 0.0062),\n",
       " ('not', 0.0057),\n",
       " ('all', 0.0047),\n",
       " ('can', 0.0046),\n",
       " ('money', 0.004),\n",
       " ('here', 0.0038),\n",
       " ('get', 0.0037),\n",
       " ('business', 0.0037),\n",
       " ('more', 0.0036),\n",
       " ('out', 0.0036),\n",
       " ('list', 0.0034),\n",
       " ('click', 0.0033),\n",
       " ('please', 0.0032),\n",
       " ('mail', 0.0031),\n",
       " ('one', 0.0031),\n",
       " ('only', 0.0031),\n",
       " ('receive', 0.003),\n",
       " ('now', 0.003),\n",
       " ('time', 0.0029),\n",
       " ('order', 0.0028),\n",
       " ('any', 0.0027),\n",
       " ('how', 0.0026),\n",
       " ('new', 0.0025),\n",
       " ('people', 0.0025),\n",
       " ('cfont', 0.0025),\n",
       " ('ffont', 0.0025),\n",
       " ('information', 0.0024),\n",
       " ('content', 0.0024),\n",
       " ('just', 0.0024),\n",
       " ('send', 0.0023),\n",
       " ('name', 0.0023),\n",
       " ('address', 0.0022),\n",
       " ('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       "  0.0022),\n",
       " ('make', 0.0022),\n",
       " ('home', 0.002),\n",
       " ('call', 0.0019),\n",
       " ('over', 0.0019),\n",
       " ('face', 0.0019),\n",
       " ('they', 0.0018),\n",
       " ('size', 0.0018),\n",
       " ('what', 0.0018),\n",
       " ('don', 0.0018),\n",
       " ('want', 0.0017),\n",
       " ('help', 0.0017),\n",
       " ('was', 0.0017),\n",
       " ('has', 0.0017),\n",
       " ('their', 0.0016),\n",
       " ('message', 0.0016),\n",
       " ('internet', 0.0016),\n",
       " ('guide', 0.0016),\n",
       " ('grants', 0.0016),\n",
       " ('below', 0.0016),\n",
       " ('mailing', 0.0016),\n",
       " ('color', 0.0016),\n",
       " ('offer', 0.0016),\n",
       " ('who', 0.0016),\n",
       " ('about', 0.0016),\n",
       " ('may', 0.0015),\n",
       " ('credit', 0.0015),\n",
       " ('government', 0.0015),\n",
       " ('like', 0.0015),\n",
       " ('them', 0.0015),\n",
       " ('report', 0.0015),\n",
       " ('type', 0.0014),\n",
       " ('been', 0.0014),\n",
       " ('software', 0.0014),\n",
       " ('removed', 0.0014),\n",
       " ('marketing', 0.0014),\n",
       " ('other', 0.0014),\n",
       " ('than', 0.0014),\n",
       " ('there', 0.0014),\n",
       " ('but', 0.0014),\n",
       " ('best', 0.0014),\n",
       " ('company', 0.0014),\n",
       " ('would', 0.0013),\n",
       " ('each', 0.0013),\n",
       " ('need', 0.0013),\n",
       " ('form', 0.0013),\n",
       " ('day', 0.0013),\n",
       " ('phone', 0.0013),\n",
       " ('million', 0.0013),\n",
       " ('special', 0.0013),\n",
       " ('work', 0.0013),\n",
       " ('web', 0.0013),\n",
       " ('online', 0.0013)]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_most_used_words = search_content_redondant_word(spam_content, 100)\n",
    "spam_most_used_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.054),\n",
       " ('and', 0.0241),\n",
       " ('that', 0.0146),\n",
       " ('for', 0.012),\n",
       " ('you', 0.0095),\n",
       " ('this', 0.0087),\n",
       " ('nbsp', 0.0085),\n",
       " ('with', 0.0078),\n",
       " ('from', 0.0064),\n",
       " ('not', 0.0058),\n",
       " ('have', 0.0054),\n",
       " ('but', 0.005),\n",
       " ('are', 0.0048),\n",
       " ('was', 0.0046),\n",
       " ('your', 0.0045),\n",
       " ('font', 0.0042),\n",
       " ('can', 0.004),\n",
       " ('all', 0.0039),\n",
       " ('has', 0.0036),\n",
       " ('they', 0.0034),\n",
       " ('list', 0.0034),\n",
       " ('one', 0.0032),\n",
       " ('linux', 0.0032),\n",
       " ('will', 0.0031),\n",
       " ('more', 0.0031),\n",
       " ('there', 0.003),\n",
       " ('about', 0.003),\n",
       " ('what', 0.0029),\n",
       " ('just', 0.0029),\n",
       " ('color', 0.0028),\n",
       " ('which', 0.0026),\n",
       " ('use', 0.0026),\n",
       " ('out', 0.0025),\n",
       " ('now', 0.0024),\n",
       " ('some', 0.0024),\n",
       " ('get', 0.0023),\n",
       " ('when', 0.0022),\n",
       " ('like', 0.0022),\n",
       " ('new', 0.0022),\n",
       " ('would', 0.0022),\n",
       " ('their', 0.0022),\n",
       " ('been', 0.0021),\n",
       " ('other', 0.0021),\n",
       " ('mail', 0.0021),\n",
       " ('only', 0.002),\n",
       " ('family', 0.002),\n",
       " ('message', 0.0019),\n",
       " ('then', 0.0019),\n",
       " ('time', 0.0019),\n",
       " ('wrote', 0.0019),\n",
       " ('size', 0.0019),\n",
       " ('than', 0.0019),\n",
       " ('its', 0.0018),\n",
       " ('text', 0.0018),\n",
       " ('don', 0.0018),\n",
       " ('our', 0.0018),\n",
       " ('any', 0.0017),\n",
       " ('web', 0.0017),\n",
       " ('also', 0.0016),\n",
       " ('date', 0.0016),\n",
       " ('arial', 0.0016),\n",
       " ('who', 0.0016),\n",
       " ('mailing', 0.0015),\n",
       " ('people', 0.0015),\n",
       " ('how', 0.0015),\n",
       " ('here', 0.0015),\n",
       " ('email', 0.0015),\n",
       " ('make', 0.0015),\n",
       " ('helvetica', 0.0015),\n",
       " ('may', 0.0014),\n",
       " ('spamassassin', 0.0014),\n",
       " ('url', 0.0014),\n",
       " ('them', 0.0014),\n",
       " ('way', 0.0014),\n",
       " ('were', 0.0014),\n",
       " ('spam', 0.0014),\n",
       " ('xml', 0.0013),\n",
       " ('system', 0.0013),\n",
       " ('said', 0.0013),\n",
       " ('_______________________________________________', 0.0013),\n",
       " ('over', 0.0013),\n",
       " ('most', 0.0013),\n",
       " ('users', 0.0013),\n",
       " ('world', 0.0013),\n",
       " ('because', 0.0013),\n",
       " ('see', 0.0013),\n",
       " ('group', 0.0013),\n",
       " ('data', 0.0012),\n",
       " ('think', 0.0012),\n",
       " ('into', 0.0012),\n",
       " ('free', 0.0012),\n",
       " ('had', 0.0012),\n",
       " ('well', 0.0012),\n",
       " ('should', 0.0012),\n",
       " ('much', 0.0012),\n",
       " ('even', 0.0012),\n",
       " ('could', 0.0012),\n",
       " ('know', 0.0012),\n",
       " ('content', 0.0012),\n",
       " ('need', 0.0012)]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_most_used_words = search_content_redondant_word(ham_content, 100)\n",
    "ham_most_used_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming, concatenate and delete redundancy\n",
    "----\n",
    "Stemming = took the root of the word -> in order to merge similar words (ex: \"use\" \"user\" \"uses\") and Concatenate lists from both spam and ham most used words and suppress doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_concatenate_most_used_word(spam_most_used, ham_most_used):\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    list_most_used_word = [ps.stem(i[0]) for i in spam_most_used]\n",
    "    list_most_used_word = list_most_used_word + [ps.stem(i[0]) for i in ham_most_used]\n",
    "    list_most_used_word = list(set(list_most_used_word))\n",
    "    \n",
    "    return list_most_used_word   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process subject\n",
    "subject_most_used_words = stem_concatenate_most_used_word(spam_subject_most_used_words, ham_subject_most_used_words)\n",
    "# Process content\n",
    "content_most_used_words = stem_concatenate_most_used_word(spam_most_used_words, ham_most_used_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_most_used_word_subject = [\n",
    "'perl',\n",
    " 'free',\n",
    " 'user',\n",
    " 'insur',\n",
    " 'from',\n",
    " 'and',\n",
    " 'for',\n",
    " 'problem',\n",
    " 'get',\n",
    " 'sadev',\n",
    " 'new',\n",
    " 'use',\n",
    " 'razor',\n",
    " 'spam',\n",
    " 'email',\n",
    " 'you',\n",
    " 'spambay',\n",
    " 'now',\n",
    " 'ilug',\n",
    " 'best',\n",
    " 'satalk',\n",
    " 'with',\n",
    " 'adv',\n",
    " 'the',\n",
    " 'market',\n",
    " 'big',\n",
    " 'mortgag',\n",
    " 'apt',\n",
    " 'your',\n",
    " 'ouch',\n",
    " 'spamassassin',\n",
    " 'wa',\n",
    " 'life',\n",
    " 'onlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perl',\n",
       " 'free',\n",
       " 'user',\n",
       " 'from',\n",
       " 'and',\n",
       " 'for',\n",
       " 'get',\n",
       " 'sadev',\n",
       " 'new',\n",
       " 'use',\n",
       " 'razor',\n",
       " 'spam',\n",
       " 'you',\n",
       " 'spambay',\n",
       " 'ilug',\n",
       " 'best',\n",
       " 'satalk',\n",
       " 'with',\n",
       " 'adv',\n",
       " 'the',\n",
       " 'mortgag',\n",
       " 'apt',\n",
       " 'your',\n",
       " 'spamassassin',\n",
       " 'wa',\n",
       " 'onlin']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_intersection = set(old_most_used_word_subject).intersection(subject_most_used_words)\n",
    "subject_intersection = list(subject_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.054),\n",
       " ('and', 0.0241),\n",
       " ('that', 0.0146),\n",
       " ('for', 0.012),\n",
       " ('you', 0.0095),\n",
       " ('this', 0.0087),\n",
       " ('nbsp', 0.0085),\n",
       " ('with', 0.0078),\n",
       " ('from', 0.0064),\n",
       " ('not', 0.0058),\n",
       " ('have', 0.0054),\n",
       " ('but', 0.005),\n",
       " ('are', 0.0048),\n",
       " ('was', 0.0046),\n",
       " ('your', 0.0045),\n",
       " ('font', 0.0042),\n",
       " ('can', 0.004),\n",
       " ('all', 0.0039),\n",
       " ('has', 0.0036),\n",
       " ('they', 0.0034),\n",
       " ('list', 0.0034),\n",
       " ('one', 0.0032),\n",
       " ('linux', 0.0032),\n",
       " ('will', 0.0031),\n",
       " ('more', 0.0031),\n",
       " ('there', 0.003),\n",
       " ('about', 0.003),\n",
       " ('what', 0.0029),\n",
       " ('just', 0.0029),\n",
       " ('color', 0.0028),\n",
       " ('which', 0.0026),\n",
       " ('use', 0.0026),\n",
       " ('out', 0.0025),\n",
       " ('now', 0.0024),\n",
       " ('some', 0.0024),\n",
       " ('get', 0.0023),\n",
       " ('when', 0.0022),\n",
       " ('like', 0.0022),\n",
       " ('new', 0.0022),\n",
       " ('would', 0.0022),\n",
       " ('their', 0.0022),\n",
       " ('been', 0.0021),\n",
       " ('other', 0.0021),\n",
       " ('mail', 0.0021),\n",
       " ('only', 0.002),\n",
       " ('family', 0.002),\n",
       " ('message', 0.0019),\n",
       " ('then', 0.0019),\n",
       " ('time', 0.0019),\n",
       " ('wrote', 0.0019),\n",
       " ('size', 0.0019),\n",
       " ('than', 0.0019),\n",
       " ('its', 0.0018),\n",
       " ('text', 0.0018),\n",
       " ('don', 0.0018),\n",
       " ('our', 0.0018),\n",
       " ('any', 0.0017),\n",
       " ('web', 0.0017),\n",
       " ('also', 0.0016),\n",
       " ('date', 0.0016),\n",
       " ('arial', 0.0016),\n",
       " ('who', 0.0016),\n",
       " ('mailing', 0.0015),\n",
       " ('people', 0.0015),\n",
       " ('how', 0.0015),\n",
       " ('here', 0.0015),\n",
       " ('email', 0.0015),\n",
       " ('make', 0.0015),\n",
       " ('helvetica', 0.0015),\n",
       " ('may', 0.0014),\n",
       " ('spamassassin', 0.0014),\n",
       " ('url', 0.0014),\n",
       " ('them', 0.0014),\n",
       " ('way', 0.0014),\n",
       " ('were', 0.0014),\n",
       " ('spam', 0.0014),\n",
       " ('xml', 0.0013),\n",
       " ('system', 0.0013),\n",
       " ('said', 0.0013),\n",
       " ('_______________________________________________', 0.0013),\n",
       " ('over', 0.0013),\n",
       " ('most', 0.0013),\n",
       " ('users', 0.0013),\n",
       " ('world', 0.0013),\n",
       " ('because', 0.0013),\n",
       " ('see', 0.0013),\n",
       " ('group', 0.0013),\n",
       " ('data', 0.0012),\n",
       " ('think', 0.0012),\n",
       " ('into', 0.0012),\n",
       " ('free', 0.0012),\n",
       " ('had', 0.0012),\n",
       " ('well', 0.0012),\n",
       " ('should', 0.0012),\n",
       " ('much', 0.0012),\n",
       " ('even', 0.0012),\n",
       " ('could', 0.0012),\n",
       " ('know', 0.0012),\n",
       " ('content', 0.0012),\n",
       " ('need', 0.0012)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_used_word_subject = [\n",
    "'perl',\n",
    " 'free',\n",
    " 'user',\n",
    " 'from',\n",
    " 'and',\n",
    " 'for',\n",
    " 'get',\n",
    " 'sadev',\n",
    " 'new',\n",
    " 'use',\n",
    " 'razor',\n",
    " 'spam',\n",
    " 'you',\n",
    " 'spambay',\n",
    " 'ilug',\n",
    " 'best',\n",
    " 'satalk',\n",
    " 'with',\n",
    " 'adv',\n",
    " 'the',\n",
    " 'mortgag',\n",
    " 'apt',\n",
    " 'your',\n",
    " 'spamassassin',\n",
    " 'wa',\n",
    " 'onlin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_most_used_word_content = [\n",
    "'phone',\n",
    " 'had',\n",
    " 'program',\n",
    " 'for',\n",
    " 'there',\n",
    " 'type',\n",
    " 'get',\n",
    " 'should',\n",
    " 'not',\n",
    " 'busi',\n",
    " 'new',\n",
    " 'them',\n",
    " 'think',\n",
    " 'web',\n",
    " 'about',\n",
    " 'world',\n",
    " 'govern',\n",
    " 'just',\n",
    " 'date',\n",
    " 'with',\n",
    " 'the',\n",
    " 'darial',\n",
    " 'other',\n",
    " 'url',\n",
    " 'see',\n",
    " 'thi',\n",
    " 'receiv',\n",
    " 'size',\n",
    " 'wa',\n",
    " 'pleas',\n",
    " 'becaus',\n",
    " 'need',\n",
    " 'state',\n",
    " 'are',\n",
    " 'click',\n",
    " 'compani',\n",
    " 'linux',\n",
    " 'today',\n",
    " 'even',\n",
    " 'insur',\n",
    " 'who',\n",
    " 'could',\n",
    " 'from',\n",
    " 'too',\n",
    " 'text',\n",
    " 'have',\n",
    " 'they',\n",
    " 'some',\n",
    " 'unit',\n",
    " 'one',\n",
    " 'also',\n",
    " 'grant',\n",
    " 'year',\n",
    " 'would',\n",
    " 'home',\n",
    " 'peopl',\n",
    " 'use',\n",
    " 'same',\n",
    " 'email',\n",
    " 'you',\n",
    " 'ani',\n",
    " 'make',\n",
    " 'those',\n",
    " 'over',\n",
    " 'cfont',\n",
    " 'out',\n",
    " 'much',\n",
    " 'inform',\n",
    " 'their',\n",
    " 'these',\n",
    " 'your',\n",
    " 'spamassassin',\n",
    " 'into',\n",
    " 'list',\n",
    " 'kingdom',\n",
    " 'more',\n",
    " 'order',\n",
    " 'nbsp',\n",
    " 'life',\n",
    " 'wrote',\n",
    " 'don',\n",
    " 'work',\n",
    " 'call',\n",
    " 'way',\n",
    " 'free',\n",
    " 'mail',\n",
    " 'and',\n",
    " 'can',\n",
    " 'then',\n",
    " 'ha',\n",
    " 'ffont',\n",
    " 'face',\n",
    " 'send',\n",
    " 'hi',\n",
    " 'now',\n",
    " 'what',\n",
    " 'time',\n",
    " 'remov',\n",
    " 'here',\n",
    " 'been',\n",
    " 'our',\n",
    " 'net',\n",
    " 'internet',\n",
    " 'than',\n",
    " 'rpm',\n",
    " 'onli',\n",
    " 'form',\n",
    " 'how',\n",
    " 'it',\n",
    " 'transfer',\n",
    " 'will',\n",
    " 'user',\n",
    " 'right',\n",
    " 'which',\n",
    " 'want',\n",
    " 'know',\n",
    " 'were',\n",
    " 'but',\n",
    " 'most',\n",
    " 'that',\n",
    " 'name',\n",
    " 'content',\n",
    " 'money',\n",
    " 'well',\n",
    " 'all',\n",
    " 'address',\n",
    " 'may',\n",
    " 'find',\n",
    " 'messag',\n",
    " 'color',\n",
    " 'when',\n",
    " 'help',\n",
    " 'enenkio',\n",
    " 'island',\n",
    " 'like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "content_intersection = set(old_most_used_word_content).intersection(content_most_used_words)\n",
    "most_used_word_content = list(content_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone',\n",
       " 'had',\n",
       " 'for',\n",
       " 'there',\n",
       " 'type',\n",
       " 'get',\n",
       " 'should',\n",
       " 'not',\n",
       " 'busi',\n",
       " 'new',\n",
       " 'them',\n",
       " 'think',\n",
       " 'web',\n",
       " 'about',\n",
       " 'world',\n",
       " 'govern',\n",
       " 'just',\n",
       " 'date',\n",
       " 'with',\n",
       " 'the',\n",
       " 'other',\n",
       " 'url',\n",
       " 'see',\n",
       " 'thi',\n",
       " 'receiv',\n",
       " 'size',\n",
       " 'wa',\n",
       " 'pleas',\n",
       " 'becaus',\n",
       " 'need',\n",
       " 'are',\n",
       " 'click',\n",
       " 'compani',\n",
       " 'linux',\n",
       " 'even',\n",
       " 'who',\n",
       " 'could',\n",
       " 'from',\n",
       " 'text',\n",
       " 'have',\n",
       " 'they',\n",
       " 'some',\n",
       " 'one',\n",
       " 'also',\n",
       " 'grant',\n",
       " 'would',\n",
       " 'home',\n",
       " 'peopl',\n",
       " 'use',\n",
       " 'email',\n",
       " 'you',\n",
       " 'ani',\n",
       " 'make',\n",
       " 'over',\n",
       " 'cfont',\n",
       " 'out',\n",
       " 'much',\n",
       " 'inform',\n",
       " 'their',\n",
       " 'your',\n",
       " 'spamassassin',\n",
       " 'into',\n",
       " 'list',\n",
       " 'more',\n",
       " 'order',\n",
       " 'nbsp',\n",
       " 'wrote',\n",
       " 'don',\n",
       " 'work',\n",
       " 'call',\n",
       " 'way',\n",
       " 'free',\n",
       " 'mail',\n",
       " 'and',\n",
       " 'can',\n",
       " 'then',\n",
       " 'ha',\n",
       " 'ffont',\n",
       " 'send',\n",
       " 'face',\n",
       " 'now',\n",
       " 'what',\n",
       " 'time',\n",
       " 'remov',\n",
       " 'here',\n",
       " 'been',\n",
       " 'our',\n",
       " 'internet',\n",
       " 'than',\n",
       " 'onli',\n",
       " 'form',\n",
       " 'how',\n",
       " 'it',\n",
       " 'will',\n",
       " 'user',\n",
       " 'which',\n",
       " 'want',\n",
       " 'know',\n",
       " 'were',\n",
       " 'but',\n",
       " 'most',\n",
       " 'that',\n",
       " 'name',\n",
       " 'content',\n",
       " 'money',\n",
       " 'well',\n",
       " 'all',\n",
       " 'address',\n",
       " 'may',\n",
       " 'messag',\n",
       " 'color',\n",
       " 'when',\n",
       " 'help',\n",
       " 'like']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_used_word_content = [\n",
    "'phone',\n",
    " 'had',\n",
    " 'for',\n",
    " 'there',\n",
    " 'type',\n",
    " 'get',\n",
    " 'should',\n",
    " 'not',\n",
    " 'busi',\n",
    " 'new',\n",
    " 'them',\n",
    " 'think',\n",
    " 'web',\n",
    " 'about',\n",
    " 'world',\n",
    " 'govern',\n",
    " 'just',\n",
    " 'date',\n",
    " 'with',\n",
    " 'the',\n",
    " 'other',\n",
    " 'url',\n",
    " 'see',\n",
    " 'thi',\n",
    " 'receiv',\n",
    " 'size',\n",
    " 'wa',\n",
    " 'pleas',\n",
    " 'becaus',\n",
    " 'need',\n",
    " 'are',\n",
    " 'click',\n",
    " 'compani',\n",
    " 'linux',\n",
    " 'even',\n",
    " 'who',\n",
    " 'could',\n",
    " 'from',\n",
    " 'text',\n",
    " 'have',\n",
    " 'they',\n",
    " 'some',\n",
    " 'one',\n",
    " 'also',\n",
    " 'grant',\n",
    " 'would',\n",
    " 'home',\n",
    " 'peopl',\n",
    " 'use',\n",
    " 'email',\n",
    " 'you',\n",
    " 'ani',\n",
    " 'make',\n",
    " 'over',\n",
    " 'cfont',\n",
    " 'out',\n",
    " 'much',\n",
    " 'inform',\n",
    " 'their',\n",
    " 'your',\n",
    " 'spamassassin',\n",
    " 'into',\n",
    " 'list',\n",
    " 'more',\n",
    " 'order',\n",
    " 'nbsp',\n",
    " 'wrote',\n",
    " 'don',\n",
    " 'work',\n",
    " 'call',\n",
    " 'way',\n",
    " 'free',\n",
    " 'mail',\n",
    " 'and',\n",
    " 'can',\n",
    " 'then',\n",
    " 'ha',\n",
    " 'ffont',\n",
    " 'send',\n",
    " 'face',\n",
    " 'now',\n",
    " 'what',\n",
    " 'time',\n",
    " 'remov',\n",
    " 'here',\n",
    " 'been',\n",
    " 'our',\n",
    " 'internet',\n",
    " 'than',\n",
    " 'onli',\n",
    " 'form',\n",
    " 'how',\n",
    " 'it',\n",
    " 'will',\n",
    " 'user',\n",
    " 'which',\n",
    " 'want',\n",
    " 'know',\n",
    " 'were',\n",
    " 'but',\n",
    " 'most',\n",
    " 'that',\n",
    " 'name',\n",
    " 'content',\n",
    " 'money',\n",
    " 'well',\n",
    " 'all',\n",
    " 'address',\n",
    " 'may',\n",
    " 'messag',\n",
    " 'color',\n",
    " 'when',\n",
    " 'help',\n",
    " 'like']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
